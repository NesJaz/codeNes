{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxFwcLUB4Mm3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def parse_image(img_path, image_size):\n",
        "    image_rgb = cv2.imread(img_path, 1)\n",
        "    h, w, _ = image_rgb.shape\n",
        "    if (h == image_size) and (w == image_size):\n",
        "        pass\n",
        "    else:\n",
        "        image_rgb = cv2.resize(image_rgb, (image_size, image_size))\n",
        "    image_rgb = image_rgb/255.0\n",
        "    return image_rgb\n",
        "\n",
        "def parse_mask(mask_path, image_size):\n",
        "    mask = cv2.imread(mask_path, -1)\n",
        "    h, w = mask.shape\n",
        "    if (h == image_size) and (w == image_size):\n",
        "        pass\n",
        "    else:\n",
        "        mask = cv2.resize(mask, (image_size, image_size))\n",
        "    mask = np.expand_dims(mask, -1)\n",
        "    mask = mask/255.0\n",
        "\n",
        "    return mask\n",
        "\n",
        "def data_gen(image_size, images_path, masks_path, batch_size=8):\n",
        "    def on_epoch_end():\n",
        "        pass\n",
        "\n",
        "    def __len__():\n",
        "        return int(np.ceil(len(images_path)/float(batch_size)))\n",
        "\n",
        "    def __getitem__(index):\n",
        "        if (index + 1) * batch_size > len(images_path):\n",
        "            batch_size_dynamic = len(images_path) - index * batch_size\n",
        "\n",
        "        images_batch = []\n",
        "        masks_batch = []\n",
        "\n",
        "        images_path_batch = images_path[index * batch_size: (index + 1) * batch_size]\n",
        "        masks_path_batch = masks_path[index * batch_size: (index + 1) * batch_size]\n",
        "\n",
        "        for i in range(len(images_path_batch)):\n",
        "            image = parse_image(images_path_batch[i], image_size)\n",
        "            mask = parse_mask(masks_path_batch[i], image_size)\n",
        "\n",
        "            images_batch.append(image)\n",
        "            masks_batch.append(mask)\n",
        "\n",
        "        return np.array(images_batch), np.array(masks_batch)\n",
        "\n",
        "    return {\n",
        "        'on_epoch_end': on_epoch_end,\n",
        "        '__len__': __len__,\n",
        "        '__getitem__': __getitem__\n",
        "    }\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "ResUNet++ architecture in Keras TensorFlow\n",
        "\"\"\"\n",
        "\n",
        "def global_context_block(input_tensor):\n",
        "    # Global average pooling to obtain global context information\n",
        "    global_context = GlobalAveragePooling2D()(input_tensor)\n",
        "    global_context = Reshape((1, 1, input_tensor.shape[-1]))(global_context)  # Reshape to match input tensor shape\n",
        "\n",
        "    # Add a 1x1 convolution to capture channel-wise dependencies\n",
        "    g_conv = Conv2D(filters=input_tensor.shape[-1], kernel_size=1, activation='relu')(global_context)  # Keep the same number of channels\n",
        "\n",
        "    # Spatial upsampling to match input tensor shape\n",
        "    g_conv = UpSampling2D(size=(input_tensor.shape[1], input_tensor.shape[2]))(g_conv)\n",
        "\n",
        "    # Multiply global context with input feature map to compute attention\n",
        "    scale = Multiply()([input_tensor, g_conv])\n",
        "\n",
        "    # Add the scaled feature map to the input tensor\n",
        "    scaled_features = Add()([input_tensor, scale])\n",
        "\n",
        "    return scaled_features\n",
        "\n",
        "def squeeze_excite_block(inputs, ratio=8):\n",
        "    init = inputs\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', use_bias=False)(se)\n",
        "\n",
        "    x = Multiply()([init, se])\n",
        "    return x\n",
        "\n",
        "def stem_block(x, n_filter, strides):\n",
        "    x_init = x\n",
        "\n",
        "    ## Conv 1\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\")(x)\n",
        "\n",
        "    ## Shortcut\n",
        "    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n",
        "    s = BatchNormalization()(s)\n",
        "\n",
        "    ## Add\n",
        "    x = Add()([x, s])\n",
        "    x = squeeze_excite_block(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_block(x, n_filter, strides=1):\n",
        "    x_init = x\n",
        "\n",
        "    ## Conv 1\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n",
        "    ## Conv 2\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=1)(x)\n",
        "\n",
        "    ## Shortcut\n",
        "    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n",
        "    s = BatchNormalization()(s)\n",
        "\n",
        "    ## Add\n",
        "    s = global_context_block(s)\n",
        "    x = Add()([x, s])\n",
        "    x = squeeze_excite_block(x)\n",
        "    return x\n",
        "\n",
        "def aspp_block(x, num_filters, rate_scale=1):\n",
        "    x1 = Conv2D(num_filters, (3, 3), dilation_rate=(4 * rate_scale, 4 * rate_scale), padding=\"same\")(x)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "\n",
        "    x2 = Conv2D(num_filters, (3, 3), dilation_rate=(8 * rate_scale, 8 * rate_scale), padding=\"same\")(x)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "\n",
        "    x3 = Conv2D(num_filters, (3, 3), dilation_rate=(16 * rate_scale, 16 * rate_scale), padding=\"same\")(x)\n",
        "    x3 = BatchNormalization()(x3)\n",
        "\n",
        "    x4 = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x4 = BatchNormalization()(x4)\n",
        "\n",
        "    y = Add()([x1, x2, x3, x4])\n",
        "    y = Conv2D(num_filters, (1, 1), padding=\"same\")(y)\n",
        "    return y\n",
        "\n",
        "def attetion_block(g, x):\n",
        "    \"\"\"\n",
        "        g: Output of Parallel Encoder block\n",
        "        x: Output of Previous Decoder block\n",
        "    \"\"\"\n",
        "\n",
        "    filters = x.shape[-1]\n",
        "\n",
        "    g_conv = BatchNormalization()(g)\n",
        "    g_conv = Activation(\"relu\")(g_conv)\n",
        "    g_conv = Conv2D(filters, (3, 3), padding=\"same\")(g_conv)\n",
        "\n",
        "    g_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(g_conv)\n",
        "\n",
        "    x_conv = BatchNormalization()(x)\n",
        "    x_conv = Activation(\"relu\")(x_conv)\n",
        "    x_conv = Conv2D(filters, (3, 3), padding=\"same\")(x_conv)\n",
        "\n",
        "    gc_sum = Add()([g_pool, x_conv])\n",
        "\n",
        "    gc_conv = BatchNormalization()(gc_sum)\n",
        "    gc_conv = Activation(\"relu\")(gc_conv)\n",
        "    gc_conv = Conv2D(filters, (3, 3), padding=\"same\")(gc_conv)\n",
        "\n",
        "    gc_mul = Multiply()([gc_conv, x])\n",
        "    return gc_mul\n",
        "\n",
        "def decoder_block(inputs, concat_tensor, filters):\n",
        "    decoder = layers.Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(inputs)\n",
        "    decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "    decoder = layers.BatchNormalization()(decoder)\n",
        "    decoder = layers.Activation('relu')(decoder)\n",
        "\n",
        "    conv11 = layers.Conv2D(filters, 3, padding = 'same')(decoder)\n",
        "    bn11 = layers.BatchNormalization(axis=3)(conv11)\n",
        "    a11 = layers.Activation(\"relu\")(bn11)\n",
        "\n",
        "    #filters-line-conv=2\n",
        "    conv21 = layers.Conv2D(filters, 3, padding = 'same')(decoder)\n",
        "    bn21 = layers.BatchNormalization(axis=3)(conv21)\n",
        "    a21 = layers.Activation(\"relu\")(bn21)\n",
        "    conv22 = layers.Conv2D(filters, 3, padding = 'same')(a21)\n",
        "    bn22 = layers.BatchNormalization(axis=3)(conv22)\n",
        "    a22 = layers.Activation(\"relu\")(bn22)\n",
        "\n",
        "    #filters-line-conv=3\n",
        "    conv31 = layers.Conv2D(filters, 3, padding = 'same')(decoder)\n",
        "    bn31 = layers.BatchNormalization(axis=3)(conv31)\n",
        "    a31 = layers.Activation(\"relu\")(bn31)\n",
        "    conv32 = layers.Conv2D(filters, 3, padding = 'same')(a31)\n",
        "    bn32 = layers.BatchNormalization(axis=3)(conv32)\n",
        "    a32 = layers.Activation(\"relu\")(bn32)\n",
        "    conv33 = layers.Conv2D(filters, 3, padding = 'same')(a32)\n",
        "    bn33 = layers.BatchNormalization(axis=3)(conv33)\n",
        "    a33 = layers.Activation(\"relu\")(bn33)\n",
        "\n",
        "\n",
        "    resout = layers.concatenate([a11,a22,a33,decoder])\n",
        "    resout = layers.Activation(\"relu\")(resout)\n",
        "\n",
        "    return resout\n",
        "\n",
        "\n",
        "def resunet_u_net(input_size=192):\n",
        "    n_filters = [16, 32, 64, 128, 256]\n",
        "    inputs = Input((input_size, input_size, 3))\n",
        "\n",
        "    # ResUNet++ Encoder\n",
        "    c0 = inputs\n",
        "    c1 = stem_block(c0, n_filters[0], strides=1)\n",
        "    c2 = resnet_block(c1, n_filters[1], strides=2)\n",
        "    c3 = resnet_block(c2, n_filters[2], strides=2)\n",
        "    c4 = resnet_block(c3, n_filters[3], strides=2)\n",
        "\n",
        "     ## Bridge\n",
        "    b1 = aspp_block(c4, n_filters[4])\n",
        "\n",
        "    # U-Net Decoder\n",
        "    d1 = attetion_block(c3, b1)\n",
        "    d1 = decoder_block(d1, c3, n_filters[3])\n",
        "\n",
        "    d2 = attetion_block(c2, d1)\n",
        "    d2 = decoder_block(d2, c2, n_filters[2])\n",
        "\n",
        "    d3 = attetion_block(c1, d2)\n",
        "    d3 = decoder_block(d3, c1, n_filters[1])\n",
        "\n",
        "    # Output\n",
        "    outputs = aspp_block(d3, n_filters[0])\n",
        "    outputs = Conv2D(1, (1, 1), padding=\"same\")(outputs)\n",
        "    outputs = Activation(\"sigmoid\")(outputs)\n",
        "\n",
        "    # Model\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "smooth = 1.\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVwJUl_o42ez",
        "outputId": "d007ab9f-8027-4101-dad0-a99a5e9af8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of augmented images in dwi1_aug: 1510\n",
            "Number of augmented images in mask2_aug: 1510\n"
          ]
        }
      ],
      "source": [
        "data_dir = '/content/drive/MyDrive/codeJournal/dwi1_aug_jpg/'\n",
        "mask_dir = '/content/drive/MyDrive/codeJournal/mask1_aug_j/'\n",
        "all_images = os.listdir(data_dir)\n",
        "\n",
        "to_train = 1 # ratio of number of tr*ain set images to use\n",
        "total_train_images = all_images[:int(len(all_images)*to_train)]\n",
        "num_augmented_images_dwi1_aug = len(os.listdir(data_dir))\n",
        "num_augmented_images_mask2_aug = len(os.listdir(mask_dir))\n",
        "print(f\"Number of augmented images in dwi1_aug: {num_augmented_images_dwi1_aug}\")\n",
        "print(f\"Number of augmented images in mask2_aug: {num_augmented_images_mask2_aug}\")\n",
        "\n",
        "WIDTH = 192\n",
        "HEIGHT = 192\n",
        "BATCH_SIZE = 8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aVqeHvuc43j9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "e2551a34-043f-4cfa-f206-5645d37c59c7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-08f6e274ee25>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_train_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "train_images, validation_images = train_test_split(total_train_images, train_size=0.8, test_size=0.2,random_state = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Dq-J2xGF49Gh",
        "outputId": "5c1f0058-492b-42a5-b5ac-de4572e98c02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n                # add random augmentation > here we only flip horizontally\\n                if np.random.random() < 1:\\n                  resized_img = resized_img.transpose(Image.FLIP_LEFT_RIGHT)\\n                  resized_mask = resized_mask.transpose(Image.FLIP_LEFT_RIGHT)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# generator that we will use to read the data from the directory\n",
        "def data_gen_small(data_dir, mask_dir, images, batch_size, dims):\n",
        "        \"\"\"\n",
        "        data_dir: where the actual images are kept\n",
        "        mask_dir: where the actual masks are kept\n",
        "        images: the filenames of the images we want to generate batches from\n",
        "        batch_size: self explanatory\n",
        "        dims: the dimensions in which we want to rescale our images, tuple\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            ix = np.random.choice(np.arange(len(images)), batch_size)\n",
        "            imgs = []\n",
        "            labels = []\n",
        "            for i in ix:\n",
        "                # images\n",
        "                original_img = load_img(data_dir + images[i])\n",
        "                resized_img = original_img.resize(dims)\n",
        "                array_img = img_to_array(resized_img)/255\n",
        "                imgs.append(array_img)\n",
        "\n",
        "                # masks\n",
        "                original_mask = load_img(mask_dir + images[i].split(\".\")[0] + '.jpg')\n",
        "                resized_mask = original_mask.resize(dims)\n",
        "                array_mask = img_to_array(resized_mask)/255\n",
        "                labels.append(array_mask[:, :, 0])\n",
        "\n",
        "            imgs = np.array(imgs)\n",
        "            labels = np.array(labels)\n",
        "            yield imgs, labels.reshape(-1, dims[0], dims[1], 1)\n",
        "\n",
        "# generator that we will use to read the data from the directory with random augmentation\n",
        "\n",
        "# generator that we will use to read the data from the directory with random augmentation\n",
        "def data_gen_aug(data_dir, mask_dir, images, batch_size, dims):\n",
        "        \"\"\"\n",
        "        data_dir: where the actual images are kept\n",
        "        mask_dir: where the actual masks are kept\n",
        "        images: the filenames of the images we want to generate batches from\n",
        "        batch_size: self explanatory\n",
        "        dims: the dimensions in which we want to rescale our images, tuple\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            ix = np.random.choice(np.arange(len(images)), batch_size)\n",
        "            imgs = []\n",
        "            labels = []\n",
        "            for i in ix:\n",
        "                # read images and masks\n",
        "                original_img = load_img(data_dir + images[i])\n",
        "                original_mask = load_img(mask_dir + images[i].split(\".\")[0] + '.jpg')\n",
        "\n",
        "                # transform into ideal sizes\n",
        "                resized_img = original_img.resize(dims)\n",
        "                resized_mask = original_mask.resize(dims)\n",
        "\n",
        "\n",
        "                array_img = img_to_array(resized_img)/255\n",
        "                array_mask = img_to_array(resized_mask)/255\n",
        "\n",
        "                imgs.append(array_img)\n",
        "                labels.append(array_mask[:, :, 0])\n",
        "\n",
        "            imgs = np.array(imgs)\n",
        "\n",
        "            labels = np.array(labels)\n",
        "            yield imgs, labels.reshape(-1, dims[0], dims[1], 1)\n",
        "'''\n",
        "                # add random augmentation > here we only flip horizontally\n",
        "                if np.random.random() < 1:\n",
        "                  resized_img = resized_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                  resized_mask = resized_mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNjzEMeZ5Djy"
      },
      "outputs": [],
      "source": [
        "#generator for train and validation data set   data_gen_aug(data_dir, mask_dir, images, batch_size, dims, seed=42)\n",
        "\n",
        "train_gen = data_gen_aug(data_dir, mask_dir, train_images, BATCH_SIZE, (WIDTH, HEIGHT))\n",
        "val_gen = data_gen_aug(data_dir, mask_dir, validation_images, BATCH_SIZE, (WIDTH, HEIGHT))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwMxTZg55EWX"
      },
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8,\n",
        "                                              restore_best_weights=False\n",
        "                                              )\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                   factor=0.2,\n",
        "                                   patience=3,\n",
        "                                   verbose=1,\n",
        "                                   min_delta=1e-3,min_lr = 1e-6\n",
        "                                   )\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfejAIjpRTgV",
        "outputId": "ef077a4c-9428-4ddd-92df-d73bd3dbe37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 192, 192, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 192, 192, 16)         448       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 192, 192, 16)         64        ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 192, 192, 16)         0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 192, 192, 16)         64        ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 192, 192, 16)         2320      ['activation_41[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 192, 192, 16)         64        ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 192, 192, 16)         0         ['conv2d_54[0][0]',           \n",
            "                                                                     'batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_7  (None, 16)                   0         ['add_12[0][0]']              \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)         (None, 1, 1, 16)             0         ['global_average_pooling2d_7[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1, 1, 2)              32        ['reshape_7[0][0]']           \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 1, 1, 16)             32        ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)      (None, 192, 192, 16)         0         ['add_12[0][0]',              \n",
            "                                                                     'dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 96, 96, 32)           544       ['multiply_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 96, 96, 32)           128       ['conv2d_58[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 192, 192, 16)         64        ['multiply_10[0][0]']         \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_8  (None, 32)                   0         ['batch_normalization_53[0][0]\n",
            "  (GlobalAveragePooling2D)                                          ']                            \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 192, 192, 16)         0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " reshape_8 (Reshape)         (None, 1, 1, 32)             0         ['global_average_pooling2d_8[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 96, 96, 32)           4640      ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 1, 1, 32)             1056      ['reshape_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 96, 96, 32)           128       ['conv2d_56[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSamplin  (None, 96, 96, 32)           0         ['conv2d_59[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 96, 96, 32)           0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)      (None, 96, 96, 32)           0         ['batch_normalization_53[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'up_sampling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 96, 96, 32)           9248      ['activation_43[0][0]']       \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 96, 96, 32)           0         ['batch_normalization_53[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'multiply_11[0][0]']         \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 96, 96, 32)           0         ['conv2d_57[0][0]',           \n",
            "                                                                     'add_13[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_9  (None, 32)                   0         ['add_14[0][0]']              \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " reshape_9 (Reshape)         (None, 1, 1, 32)             0         ['global_average_pooling2d_9[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 1, 1, 4)              128       ['reshape_9[0][0]']           \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 1, 1, 32)             128       ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)      (None, 96, 96, 32)           0         ['add_14[0][0]',              \n",
            "                                                                     'dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 48, 48, 64)           2112      ['multiply_12[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 48, 48, 64)           256       ['conv2d_62[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 96, 96, 32)           128       ['multiply_12[0][0]']         \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 64)                   0         ['batch_normalization_56[0][0]\n",
            " 0 (GlobalAveragePooling2D)                                         ']                            \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 96, 96, 32)           0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " reshape_10 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_10[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 48, 48, 64)           18496     ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 1, 1, 64)             4160      ['reshape_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 48, 48, 64)           256       ['conv2d_60[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSamplin  (None, 48, 48, 64)           0         ['conv2d_63[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 48, 48, 64)           0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)      (None, 48, 48, 64)           0         ['batch_normalization_56[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'up_sampling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 48, 48, 64)           36928     ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " add_15 (Add)                (None, 48, 48, 64)           0         ['batch_normalization_56[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'multiply_13[0][0]']         \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 48, 48, 64)           0         ['conv2d_61[0][0]',           \n",
            "                                                                     'add_15[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 64)                   0         ['add_16[0][0]']              \n",
            " 1 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_11 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_11[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 1, 1, 8)              512       ['reshape_11[0][0]']          \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 1, 1, 64)             512       ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)      (None, 48, 48, 64)           0         ['add_16[0][0]',              \n",
            "                                                                     'dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 24, 24, 128)          8320      ['multiply_14[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 24, 24, 128)          512       ['conv2d_66[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 48, 48, 64)           256       ['multiply_14[0][0]']         \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 128)                  0         ['batch_normalization_59[0][0]\n",
            " 2 (GlobalAveragePooling2D)                                         ']                            \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 48, 48, 64)           0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)        (None, 1, 1, 128)            0         ['global_average_pooling2d_12[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 24, 24, 128)          73856     ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 1, 1, 128)            16512     ['reshape_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 24, 24, 128)          512       ['conv2d_64[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSamplin  (None, 24, 24, 128)          0         ['conv2d_67[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 24, 24, 128)          0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)      (None, 24, 24, 128)          0         ['batch_normalization_59[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'up_sampling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 24, 24, 128)          147584    ['activation_47[0][0]']       \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 24, 24, 128)          0         ['batch_normalization_59[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'multiply_15[0][0]']         \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 24, 24, 128)          0         ['conv2d_65[0][0]',           \n",
            "                                                                     'add_17[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 128)                  0         ['add_18[0][0]']              \n",
            " 3 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)        (None, 1, 1, 128)            0         ['global_average_pooling2d_13[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 1, 1, 16)             2048      ['reshape_13[0][0]']          \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 1, 1, 128)            2048      ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)      (None, 24, 24, 128)          0         ['add_18[0][0]',              \n",
            "                                                                     'dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 24, 24, 256)          295168    ['multiply_16[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 24, 24, 256)          295168    ['multiply_16[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 24, 24, 256)          295168    ['multiply_16[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 24, 24, 256)          295168    ['multiply_16[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 24, 24, 256)          1024      ['conv2d_68[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 24, 24, 256)          1024      ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 24, 24, 256)          1024      ['conv2d_70[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 24, 24, 256)          1024      ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_19 (Add)                (None, 24, 24, 256)          0         ['batch_normalization_60[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_61[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_62[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 48, 48, 64)           256       ['multiply_14[0][0]']         \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 24, 24, 256)          65792     ['add_19[0][0]']              \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 48, 48, 64)           0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 24, 24, 256)          1024      ['conv2d_72[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 48, 48, 256)          147712    ['activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 24, 24, 256)          0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 24, 24, 256)          0         ['conv2d_73[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 24, 24, 256)          590080    ['activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " add_20 (Add)                (None, 24, 24, 256)          0         ['max_pooling2d_3[0][0]',     \n",
            "                                                                     'conv2d_74[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 24, 24, 256)          1024      ['add_20[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 24, 24, 256)          0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 24, 24, 256)          590080    ['activation_50[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)      (None, 24, 24, 256)          0         ['conv2d_75[0][0]',           \n",
            "                                                                     'conv2d_72[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 48, 48, 128)          131200    ['multiply_17[0][0]']         \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 48, 48, 192)          0         ['multiply_14[0][0]',         \n",
            " )                                                                   'conv2d_transpose_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 48, 48, 192)          768       ['concatenate_6[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 48, 48, 192)          0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)          (None, 48, 48, 128)          221312    ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 48, 48, 128)          512       ['conv2d_79[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_55 (Activation)  (None, 48, 48, 128)          0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)          (None, 48, 48, 128)          221312    ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)          (None, 48, 48, 128)          147584    ['activation_55[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 48, 48, 128)          512       ['conv2d_77[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 48, 48, 128)          512       ['conv2d_80[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 48, 48, 128)          0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_56 (Activation)  (None, 48, 48, 128)          0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)          (None, 48, 48, 128)          221312    ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)          (None, 48, 48, 128)          147584    ['activation_53[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)          (None, 48, 48, 128)          147584    ['activation_56[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 48, 48, 128)          512       ['conv2d_76[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 48, 48, 128)          512       ['conv2d_78[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 48, 48, 128)          512       ['conv2d_81[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 48, 48, 128)          0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_54 (Activation)  (None, 48, 48, 128)          0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 48, 48, 128)          0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 48, 48, 576)          0         ['activation_52[0][0]',       \n",
            " )                                                                   'activation_54[0][0]',       \n",
            "                                                                     'activation_57[0][0]',       \n",
            "                                                                     'activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 96, 96, 32)           128       ['multiply_12[0][0]']         \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 48, 48, 576)          0         ['concatenate_7[0][0]']       \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 96, 96, 32)           0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 48, 48, 576)          2304      ['activation_58[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)          (None, 96, 96, 576)          166464    ['activation_59[0][0]']       \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 48, 48, 576)          0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 48, 48, 576)          0         ['conv2d_82[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)          (None, 48, 48, 576)          2986560   ['activation_60[0][0]']       \n",
            "                                                                                                  \n",
            " add_21 (Add)                (None, 48, 48, 576)          0         ['max_pooling2d_4[0][0]',     \n",
            "                                                                     'conv2d_83[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_76 (Ba  (None, 48, 48, 576)          2304      ['add_21[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 48, 48, 576)          0         ['batch_normalization_76[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)          (None, 48, 48, 576)          2986560   ['activation_61[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)      (None, 48, 48, 576)          0         ['conv2d_84[0][0]',           \n",
            "                                                                     'activation_58[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 96, 96, 64)           147520    ['multiply_18[0][0]']         \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 96, 96, 96)           0         ['multiply_12[0][0]',         \n",
            " )                                                                   'conv2d_transpose_4[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_77 (Ba  (None, 96, 96, 96)           384       ['concatenate_8[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 96, 96, 96)           0         ['batch_normalization_77[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)          (None, 96, 96, 64)           55360     ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_81 (Ba  (None, 96, 96, 64)           256       ['conv2d_88[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 96, 96, 64)           0         ['batch_normalization_81[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)          (None, 96, 96, 64)           55360     ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 96, 96, 64)           36928     ['activation_66[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_79 (Ba  (None, 96, 96, 64)           256       ['conv2d_86[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_82 (Ba  (None, 96, 96, 64)           256       ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 96, 96, 64)           0         ['batch_normalization_79[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 96, 96, 64)           0         ['batch_normalization_82[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)          (None, 96, 96, 64)           55360     ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)          (None, 96, 96, 64)           36928     ['activation_64[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 96, 96, 64)           36928     ['activation_67[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_78 (Ba  (None, 96, 96, 64)           256       ['conv2d_85[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_80 (Ba  (None, 96, 96, 64)           256       ['conv2d_87[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_83 (Ba  (None, 96, 96, 64)           256       ['conv2d_90[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 96, 96, 64)           0         ['batch_normalization_78[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 96, 96, 64)           0         ['batch_normalization_80[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_68 (Activation)  (None, 96, 96, 64)           0         ['batch_normalization_83[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 96, 96, 288)          0         ['activation_63[0][0]',       \n",
            " )                                                                   'activation_65[0][0]',       \n",
            "                                                                     'activation_68[0][0]',       \n",
            "                                                                     'activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_84 (Ba  (None, 192, 192, 16)         64        ['multiply_10[0][0]']         \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_69 (Activation)  (None, 96, 96, 288)          0         ['concatenate_9[0][0]']       \n",
            "                                                                                                  \n",
            " activation_70 (Activation)  (None, 192, 192, 16)         0         ['batch_normalization_84[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_85 (Ba  (None, 96, 96, 288)          1152      ['activation_69[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 192, 192, 288)        41760     ['activation_70[0][0]']       \n",
            "                                                                                                  \n",
            " activation_71 (Activation)  (None, 96, 96, 288)          0         ['batch_normalization_85[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 96, 96, 288)          0         ['conv2d_91[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 96, 96, 288)          746784    ['activation_71[0][0]']       \n",
            "                                                                                                  \n",
            " add_22 (Add)                (None, 96, 96, 288)          0         ['max_pooling2d_5[0][0]',     \n",
            "                                                                     'conv2d_92[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_86 (Ba  (None, 96, 96, 288)          1152      ['add_22[0][0]']              \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)  (None, 96, 96, 288)          0         ['batch_normalization_86[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 96, 96, 288)          746784    ['activation_72[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)      (None, 96, 96, 288)          0         ['conv2d_93[0][0]',           \n",
            "                                                                     'activation_69[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 192, 192, 32)         36896     ['multiply_19[0][0]']         \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 192, 192, 48)         0         ['multiply_10[0][0]',         \n",
            " e)                                                                  'conv2d_transpose_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_87 (Ba  (None, 192, 192, 48)         192       ['concatenate_10[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_73 (Activation)  (None, 192, 192, 48)         0         ['batch_normalization_87[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)          (None, 192, 192, 32)         13856     ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_91 (Ba  (None, 192, 192, 32)         128       ['conv2d_97[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_77 (Activation)  (None, 192, 192, 32)         0         ['batch_normalization_91[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)          (None, 192, 192, 32)         13856     ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)          (None, 192, 192, 32)         9248      ['activation_77[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_89 (Ba  (None, 192, 192, 32)         128       ['conv2d_95[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_92 (Ba  (None, 192, 192, 32)         128       ['conv2d_98[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_75 (Activation)  (None, 192, 192, 32)         0         ['batch_normalization_89[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_78 (Activation)  (None, 192, 192, 32)         0         ['batch_normalization_92[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)          (None, 192, 192, 32)         13856     ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)          (None, 192, 192, 32)         9248      ['activation_75[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)          (None, 192, 192, 32)         9248      ['activation_78[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_88 (Ba  (None, 192, 192, 32)         128       ['conv2d_94[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_90 (Ba  (None, 192, 192, 32)         128       ['conv2d_96[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_93 (Ba  (None, 192, 192, 32)         128       ['conv2d_99[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_74 (Activation)  (None, 192, 192, 32)         0         ['batch_normalization_88[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_76 (Activation)  (None, 192, 192, 32)         0         ['batch_normalization_90[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_79 (Activation)  (None, 192, 192, 32)         0         ['batch_normalization_93[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 192, 192, 144)        0         ['activation_74[0][0]',       \n",
            " e)                                                                  'activation_76[0][0]',       \n",
            "                                                                     'activation_79[0][0]',       \n",
            "                                                                     'activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " activation_80 (Activation)  (None, 192, 192, 144)        0         ['concatenate_11[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)         (None, 192, 192, 16)         20752     ['activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)         (None, 192, 192, 16)         20752     ['activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)         (None, 192, 192, 16)         20752     ['activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)         (None, 192, 192, 16)         20752     ['activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_94 (Ba  (None, 192, 192, 16)         64        ['conv2d_100[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_95 (Ba  (None, 192, 192, 16)         64        ['conv2d_101[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_96 (Ba  (None, 192, 192, 16)         64        ['conv2d_102[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_97 (Ba  (None, 192, 192, 16)         64        ['conv2d_103[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_23 (Add)                (None, 192, 192, 16)         0         ['batch_normalization_94[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_95[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_96[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_97[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)         (None, 192, 192, 16)         272       ['add_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)         (None, 192, 192, 1)          17        ['conv2d_104[0][0]']          \n",
            "                                                                                                  \n",
            " activation_81 (Activation)  (None, 192, 192, 1)          0         ['conv2d_105[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 12455601 (47.51 MB)\n",
            "Trainable params: 12444177 (47.47 MB)\n",
            "Non-trainable params: 11424 (44.62 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "arch = resunet_u_net()\n",
        "arch.summary()\n",
        "tf.keras.utils.plot_model(arch,to_file='model.png')\n",
        "model = arch\n",
        "image_size = 192\n",
        "lr = 1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NRRrx2se5NST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "42e9cb81-02dd-46b3-867d-de8fc96502ee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-45308df35d14>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdice_coef\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer = adam, loss = BinaryCrossentropy(), metrics=['accuracy',dice_coef])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfSAmsjkwBS3",
        "outputId": "65e4ef4d-b5c7-4f19-9295-1d10240abf40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0269 - accuracy: 0.9800 - dice_coef: 0.5230 - val_loss: 0.0294 - val_accuracy: 0.9775 - val_dice_coef: 0.5161\n",
            "Epoch 2/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0327 - accuracy: 0.9799 - dice_coef: 0.5294 - val_loss: 0.0337 - val_accuracy: 0.9772 - val_dice_coef: 0.4863\n",
            "Epoch 3/100\n",
            "151/151 [==============================] - 100s 661ms/step - loss: 0.0250 - accuracy: 0.9803 - dice_coef: 0.5793 - val_loss: 0.0212 - val_accuracy: 0.9803 - val_dice_coef: 0.5696\n",
            "Epoch 4/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0205 - accuracy: 0.9815 - dice_coef: 0.5859 - val_loss: 0.0254 - val_accuracy: 0.9779 - val_dice_coef: 0.6176\n",
            "Epoch 5/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0197 - accuracy: 0.9804 - dice_coef: 0.6177 - val_loss: 0.0249 - val_accuracy: 0.9785 - val_dice_coef: 0.6334\n",
            "Epoch 6/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0222 - accuracy: 0.9794 - dice_coef: 0.6019 - val_loss: 0.0165 - val_accuracy: 0.9806 - val_dice_coef: 0.6128\n",
            "Epoch 7/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0196 - accuracy: 0.9806 - dice_coef: 0.6168 - val_loss: 0.0212 - val_accuracy: 0.9780 - val_dice_coef: 0.6130\n",
            "Epoch 8/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0175 - accuracy: 0.9806 - dice_coef: 0.6430 - val_loss: 0.0183 - val_accuracy: 0.9800 - val_dice_coef: 0.6523\n",
            "Epoch 9/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0194 - accuracy: 0.9811 - dice_coef: 0.6281 - val_loss: 0.0162 - val_accuracy: 0.9808 - val_dice_coef: 0.6496\n",
            "Epoch 10/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0178 - accuracy: 0.9798 - dice_coef: 0.6291 - val_loss: 0.0179 - val_accuracy: 0.9790 - val_dice_coef: 0.6211\n",
            "Epoch 11/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0162 - accuracy: 0.9807 - dice_coef: 0.6673 - val_loss: 0.0171 - val_accuracy: 0.9798 - val_dice_coef: 0.6721\n",
            "Epoch 12/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0152 - accuracy: 0.9810 - dice_coef: 0.6727 - val_loss: 0.0142 - val_accuracy: 0.9805 - val_dice_coef: 0.6922\n",
            "Epoch 13/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0148 - accuracy: 0.9809 - dice_coef: 0.6835 - val_loss: 0.0211 - val_accuracy: 0.9791 - val_dice_coef: 0.7063\n",
            "Epoch 14/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0142 - accuracy: 0.9814 - dice_coef: 0.6878 - val_loss: 0.0160 - val_accuracy: 0.9790 - val_dice_coef: 0.7153\n",
            "Epoch 15/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0129 - accuracy: 0.9815 - dice_coef: 0.6977 - val_loss: 0.0126 - val_accuracy: 0.9802 - val_dice_coef: 0.7068\n",
            "Epoch 16/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0127 - accuracy: 0.9816 - dice_coef: 0.7150 - val_loss: 0.0162 - val_accuracy: 0.9786 - val_dice_coef: 0.6719\n",
            "Epoch 17/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0126 - accuracy: 0.9808 - dice_coef: 0.7189 - val_loss: 0.0198 - val_accuracy: 0.9785 - val_dice_coef: 0.6922\n",
            "Epoch 18/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0123 - accuracy: 0.9815 - dice_coef: 0.7154 - val_loss: 0.0163 - val_accuracy: 0.9805 - val_dice_coef: 0.7203\n",
            "Epoch 19/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0123 - accuracy: 0.9809 - dice_coef: 0.7330 - val_loss: 0.0177 - val_accuracy: 0.9808 - val_dice_coef: 0.7087\n",
            "Epoch 20/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0119 - accuracy: 0.9817 - dice_coef: 0.7287 - val_loss: 0.0127 - val_accuracy: 0.9804 - val_dice_coef: 0.7446\n",
            "Epoch 21/100\n",
            "151/151 [==============================] - 100s 661ms/step - loss: 0.0491 - accuracy: 0.9787 - dice_coef: 0.5817 - val_loss: 0.0963 - val_accuracy: 0.9770 - val_dice_coef: 0.5764\n",
            "Epoch 22/100\n",
            "151/151 [==============================] - 100s 660ms/step - loss: 0.0215 - accuracy: 0.9806 - dice_coef: 0.6256 - val_loss: 0.0254 - val_accuracy: 0.9780 - val_dice_coef: 0.6525\n",
            "Epoch 23/100\n",
            "151/151 [==============================] - 100s 660ms/step - loss: 0.0188 - accuracy: 0.9798 - dice_coef: 0.6491 - val_loss: 0.0193 - val_accuracy: 0.9791 - val_dice_coef: 0.6360\n",
            "Epoch 24/100\n",
            "151/151 [==============================] - 100s 660ms/step - loss: 0.0183 - accuracy: 0.9801 - dice_coef: 0.6518 - val_loss: 0.0262 - val_accuracy: 0.9784 - val_dice_coef: 0.6615\n",
            "Epoch 25/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0163 - accuracy: 0.9813 - dice_coef: 0.6577 - val_loss: 0.0168 - val_accuracy: 0.9792 - val_dice_coef: 0.6719\n",
            "Epoch 26/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0154 - accuracy: 0.9806 - dice_coef: 0.6897 - val_loss: 0.0148 - val_accuracy: 0.9795 - val_dice_coef: 0.7066\n",
            "Epoch 27/100\n",
            "151/151 [==============================] - 100s 660ms/step - loss: 0.0138 - accuracy: 0.9817 - dice_coef: 0.6962 - val_loss: 0.0136 - val_accuracy: 0.9804 - val_dice_coef: 0.7170\n",
            "Epoch 28/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0136 - accuracy: 0.9807 - dice_coef: 0.7107 - val_loss: 0.0131 - val_accuracy: 0.9819 - val_dice_coef: 0.7396\n",
            "Epoch 29/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0123 - accuracy: 0.9816 - dice_coef: 0.7199 - val_loss: 0.0148 - val_accuracy: 0.9795 - val_dice_coef: 0.7353\n",
            "Epoch 30/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0137 - accuracy: 0.9808 - dice_coef: 0.7122 - val_loss: 0.0106 - val_accuracy: 0.9811 - val_dice_coef: 0.7455\n",
            "Epoch 31/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0127 - accuracy: 0.9816 - dice_coef: 0.7099 - val_loss: 0.0164 - val_accuracy: 0.9796 - val_dice_coef: 0.7139\n",
            "Epoch 32/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0124 - accuracy: 0.9813 - dice_coef: 0.7254 - val_loss: 0.0134 - val_accuracy: 0.9786 - val_dice_coef: 0.7609\n",
            "Epoch 33/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0118 - accuracy: 0.9812 - dice_coef: 0.7304 - val_loss: 0.0120 - val_accuracy: 0.9798 - val_dice_coef: 0.7645\n",
            "Epoch 34/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0118 - accuracy: 0.9813 - dice_coef: 0.7369 - val_loss: 0.0108 - val_accuracy: 0.9814 - val_dice_coef: 0.7332\n",
            "Epoch 35/100\n",
            "151/151 [==============================] - 100s 660ms/step - loss: 0.0115 - accuracy: 0.9815 - dice_coef: 0.7374 - val_loss: 0.0114 - val_accuracy: 0.9800 - val_dice_coef: 0.7671\n",
            "Epoch 36/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0106 - accuracy: 0.9823 - dice_coef: 0.7365 - val_loss: 0.0142 - val_accuracy: 0.9779 - val_dice_coef: 0.7441\n",
            "Epoch 37/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0108 - accuracy: 0.9813 - dice_coef: 0.7552 - val_loss: 0.0101 - val_accuracy: 0.9817 - val_dice_coef: 0.7589\n",
            "Epoch 38/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0104 - accuracy: 0.9815 - dice_coef: 0.7541 - val_loss: 0.0135 - val_accuracy: 0.9807 - val_dice_coef: 0.7554\n",
            "Epoch 39/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0107 - accuracy: 0.9812 - dice_coef: 0.7578 - val_loss: 0.0120 - val_accuracy: 0.9817 - val_dice_coef: 0.7148\n",
            "Epoch 40/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0108 - accuracy: 0.9814 - dice_coef: 0.7558 - val_loss: 0.0157 - val_accuracy: 0.9776 - val_dice_coef: 0.7292\n",
            "Epoch 41/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0109 - accuracy: 0.9814 - dice_coef: 0.7567 - val_loss: 0.0120 - val_accuracy: 0.9797 - val_dice_coef: 0.7443\n",
            "Epoch 42/100\n",
            "151/151 [==============================] - 100s 661ms/step - loss: 0.0100 - accuracy: 0.9816 - dice_coef: 0.7652 - val_loss: 0.0118 - val_accuracy: 0.9801 - val_dice_coef: 0.7527\n",
            "Epoch 43/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0099 - accuracy: 0.9815 - dice_coef: 0.7661 - val_loss: 0.0128 - val_accuracy: 0.9782 - val_dice_coef: 0.7704\n",
            "Epoch 44/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0102 - accuracy: 0.9823 - dice_coef: 0.7508 - val_loss: 0.0146 - val_accuracy: 0.9788 - val_dice_coef: 0.7230\n",
            "Epoch 45/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0106 - accuracy: 0.9809 - dice_coef: 0.7533 - val_loss: 0.0153 - val_accuracy: 0.9810 - val_dice_coef: 0.7710\n",
            "Epoch 46/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0107 - accuracy: 0.9802 - dice_coef: 0.7626 - val_loss: 0.0109 - val_accuracy: 0.9799 - val_dice_coef: 0.7638\n",
            "Epoch 47/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0096 - accuracy: 0.9813 - dice_coef: 0.7780 - val_loss: 0.0108 - val_accuracy: 0.9803 - val_dice_coef: 0.7940\n",
            "Epoch 48/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0091 - accuracy: 0.9820 - dice_coef: 0.7787 - val_loss: 0.0106 - val_accuracy: 0.9806 - val_dice_coef: 0.7955\n",
            "Epoch 49/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0097 - accuracy: 0.9818 - dice_coef: 0.7677 - val_loss: 0.0117 - val_accuracy: 0.9799 - val_dice_coef: 0.7750\n",
            "Epoch 50/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0092 - accuracy: 0.9817 - dice_coef: 0.7770 - val_loss: 0.0104 - val_accuracy: 0.9816 - val_dice_coef: 0.7604\n",
            "Epoch 51/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0090 - accuracy: 0.9823 - dice_coef: 0.7692 - val_loss: 0.0092 - val_accuracy: 0.9809 - val_dice_coef: 0.8002\n",
            "Epoch 52/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0083 - accuracy: 0.9829 - dice_coef: 0.7825 - val_loss: 0.0129 - val_accuracy: 0.9805 - val_dice_coef: 0.7818\n",
            "Epoch 53/100\n",
            "151/151 [==============================] - 100s 661ms/step - loss: 0.0097 - accuracy: 0.9807 - dice_coef: 0.7783 - val_loss: 0.0110 - val_accuracy: 0.9813 - val_dice_coef: 0.7558\n",
            "Epoch 54/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0094 - accuracy: 0.9812 - dice_coef: 0.7837 - val_loss: 0.0096 - val_accuracy: 0.9816 - val_dice_coef: 0.7551\n",
            "Epoch 55/100\n",
            "151/151 [==============================] - 100s 661ms/step - loss: 0.0091 - accuracy: 0.9819 - dice_coef: 0.7797 - val_loss: 0.0100 - val_accuracy: 0.9813 - val_dice_coef: 0.7681\n",
            "Epoch 56/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0093 - accuracy: 0.9814 - dice_coef: 0.7838 - val_loss: 0.0090 - val_accuracy: 0.9820 - val_dice_coef: 0.7829\n",
            "Epoch 57/100\n",
            "151/151 [==============================] - 100s 662ms/step - loss: 0.0120 - accuracy: 0.9813 - dice_coef: 0.7436 - val_loss: 0.0132 - val_accuracy: 0.9788 - val_dice_coef: 0.7619\n",
            "Epoch 58/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0098 - accuracy: 0.9819 - dice_coef: 0.7645 - val_loss: 0.0127 - val_accuracy: 0.9810 - val_dice_coef: 0.7460\n",
            "Epoch 59/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0096 - accuracy: 0.9812 - dice_coef: 0.7783 - val_loss: 0.0095 - val_accuracy: 0.9813 - val_dice_coef: 0.7826\n",
            "Epoch 60/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0092 - accuracy: 0.9809 - dice_coef: 0.7891 - val_loss: 0.0096 - val_accuracy: 0.9812 - val_dice_coef: 0.7818\n",
            "Epoch 61/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0089 - accuracy: 0.9807 - dice_coef: 0.7989 - val_loss: 0.0095 - val_accuracy: 0.9802 - val_dice_coef: 0.7967\n",
            "Epoch 62/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0085 - accuracy: 0.9819 - dice_coef: 0.7849 - val_loss: 0.0083 - val_accuracy: 0.9821 - val_dice_coef: 0.7782\n",
            "Epoch 63/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0086 - accuracy: 0.9814 - dice_coef: 0.7892 - val_loss: 0.0111 - val_accuracy: 0.9815 - val_dice_coef: 0.7623\n",
            "Epoch 64/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0081 - accuracy: 0.9825 - dice_coef: 0.7908 - val_loss: 0.0093 - val_accuracy: 0.9796 - val_dice_coef: 0.7996\n",
            "Epoch 65/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0079 - accuracy: 0.9819 - dice_coef: 0.7984 - val_loss: 0.0085 - val_accuracy: 0.9813 - val_dice_coef: 0.8022\n",
            "Epoch 66/100\n",
            "151/151 [==============================] - 100s 663ms/step - loss: 0.0082 - accuracy: 0.9816 - dice_coef: 0.7972 - val_loss: 0.0097 - val_accuracy: 0.9813 - val_dice_coef: 0.7876\n",
            "Epoch 67/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0091 - accuracy: 0.9815 - dice_coef: 0.7786 - val_loss: 0.0110 - val_accuracy: 0.9804 - val_dice_coef: 0.7752\n",
            "Epoch 68/100\n",
            "151/151 [==============================] - 100s 664ms/step - loss: 0.0082 - accuracy: 0.9819 - dice_coef: 0.7989 - val_loss: 0.0203 - val_accuracy: 0.9807 - val_dice_coef: 0.7668\n",
            "Epoch 69/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0081 - accuracy: 0.9821 - dice_coef: 0.7907 - val_loss: 0.0087 - val_accuracy: 0.9814 - val_dice_coef: 0.7951\n",
            "Epoch 70/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0080 - accuracy: 0.9812 - dice_coef: 0.8053 - val_loss: 0.0093 - val_accuracy: 0.9804 - val_dice_coef: 0.8155\n",
            "Epoch 71/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0077 - accuracy: 0.9817 - dice_coef: 0.8056 - val_loss: 0.0112 - val_accuracy: 0.9795 - val_dice_coef: 0.8125\n",
            "Epoch 72/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0081 - accuracy: 0.9811 - dice_coef: 0.8053 - val_loss: 0.0088 - val_accuracy: 0.9813 - val_dice_coef: 0.8146\n",
            "Epoch 73/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0075 - accuracy: 0.9818 - dice_coef: 0.8059 - val_loss: 0.0101 - val_accuracy: 0.9805 - val_dice_coef: 0.8015\n",
            "Epoch 74/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0077 - accuracy: 0.9818 - dice_coef: 0.8081 - val_loss: 0.0150 - val_accuracy: 0.9804 - val_dice_coef: 0.7970\n",
            "Epoch 75/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0104 - accuracy: 0.9810 - dice_coef: 0.7658 - val_loss: 0.0112 - val_accuracy: 0.9793 - val_dice_coef: 0.7514\n",
            "Epoch 76/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0087 - accuracy: 0.9812 - dice_coef: 0.7909 - val_loss: 0.0098 - val_accuracy: 0.9810 - val_dice_coef: 0.7550\n",
            "Epoch 77/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0083 - accuracy: 0.9812 - dice_coef: 0.8027 - val_loss: 0.0086 - val_accuracy: 0.9815 - val_dice_coef: 0.7923\n",
            "Epoch 78/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0077 - accuracy: 0.9810 - dice_coef: 0.8111 - val_loss: 0.0086 - val_accuracy: 0.9805 - val_dice_coef: 0.8190\n",
            "Epoch 79/100\n",
            "151/151 [==============================] - 101s 667ms/step - loss: 0.0074 - accuracy: 0.9818 - dice_coef: 0.8168 - val_loss: 0.0093 - val_accuracy: 0.9802 - val_dice_coef: 0.7857\n",
            "Epoch 80/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0101 - accuracy: 0.9818 - dice_coef: 0.7530 - val_loss: 0.0155 - val_accuracy: 0.9796 - val_dice_coef: 0.7701\n",
            "Epoch 81/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0087 - accuracy: 0.9807 - dice_coef: 0.7968 - val_loss: 0.0112 - val_accuracy: 0.9819 - val_dice_coef: 0.7171\n",
            "Epoch 82/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0074 - accuracy: 0.9816 - dice_coef: 0.8104 - val_loss: 0.0081 - val_accuracy: 0.9815 - val_dice_coef: 0.7997\n",
            "Epoch 83/100\n",
            "151/151 [==============================] - 101s 667ms/step - loss: 0.0072 - accuracy: 0.9816 - dice_coef: 0.8194 - val_loss: 0.0084 - val_accuracy: 0.9815 - val_dice_coef: 0.8006\n",
            "Epoch 84/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0065 - accuracy: 0.9827 - dice_coef: 0.8209 - val_loss: 0.0092 - val_accuracy: 0.9803 - val_dice_coef: 0.8194\n",
            "Epoch 85/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0070 - accuracy: 0.9817 - dice_coef: 0.8249 - val_loss: 0.0081 - val_accuracy: 0.9811 - val_dice_coef: 0.8315\n",
            "Epoch 86/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0068 - accuracy: 0.9823 - dice_coef: 0.8189 - val_loss: 0.0433 - val_accuracy: 0.9784 - val_dice_coef: 0.7663\n",
            "Epoch 87/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0070 - accuracy: 0.9822 - dice_coef: 0.8195 - val_loss: 0.0083 - val_accuracy: 0.9798 - val_dice_coef: 0.8148\n",
            "Epoch 88/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0069 - accuracy: 0.9815 - dice_coef: 0.8286 - val_loss: 0.0084 - val_accuracy: 0.9815 - val_dice_coef: 0.8218\n",
            "Epoch 89/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0073 - accuracy: 0.9817 - dice_coef: 0.8112 - val_loss: 0.0098 - val_accuracy: 0.9804 - val_dice_coef: 0.7899\n",
            "Epoch 90/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0074 - accuracy: 0.9818 - dice_coef: 0.8154 - val_loss: 0.0125 - val_accuracy: 0.9811 - val_dice_coef: 0.8096\n",
            "Epoch 91/100\n",
            "151/151 [==============================] - 101s 666ms/step - loss: 0.0066 - accuracy: 0.9822 - dice_coef: 0.8314 - val_loss: 0.0094 - val_accuracy: 0.9800 - val_dice_coef: 0.8313\n",
            "Epoch 92/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0068 - accuracy: 0.9818 - dice_coef: 0.8274 - val_loss: 0.0096 - val_accuracy: 0.9801 - val_dice_coef: 0.8175\n",
            "Epoch 93/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0065 - accuracy: 0.9820 - dice_coef: 0.8329 - val_loss: 0.0087 - val_accuracy: 0.9808 - val_dice_coef: 0.8193\n",
            "Epoch 94/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0065 - accuracy: 0.9821 - dice_coef: 0.8284 - val_loss: 0.0160 - val_accuracy: 0.9793 - val_dice_coef: 0.7967\n",
            "Epoch 95/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0066 - accuracy: 0.9819 - dice_coef: 0.8219 - val_loss: 0.0082 - val_accuracy: 0.9814 - val_dice_coef: 0.8178\n",
            "Epoch 96/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0064 - accuracy: 0.9821 - dice_coef: 0.8272 - val_loss: 0.0085 - val_accuracy: 0.9816 - val_dice_coef: 0.8023\n",
            "Epoch 97/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0078 - accuracy: 0.9818 - dice_coef: 0.8063 - val_loss: 0.0103 - val_accuracy: 0.9803 - val_dice_coef: 0.8123\n",
            "Epoch 98/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0070 - accuracy: 0.9816 - dice_coef: 0.8163 - val_loss: 0.0115 - val_accuracy: 0.9791 - val_dice_coef: 0.8127\n",
            "Epoch 99/100\n",
            "151/151 [==============================] - 100s 665ms/step - loss: 0.0065 - accuracy: 0.9821 - dice_coef: 0.8297 - val_loss: 0.0087 - val_accuracy: 0.9789 - val_dice_coef: 0.8177\n",
            "Epoch 100/100\n",
            "151/151 [==============================] - 100s 666ms/step - loss: 0.0067 - accuracy: 0.9818 - dice_coef: 0.8274 - val_loss: 0.0105 - val_accuracy: 0.9818 - val_dice_coef: 0.7656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "hist=model.fit(train_gen,\n",
        "                    steps_per_epoch=np.ceil(float(len(train_images)) / float(BATCH_SIZE)),\n",
        "                    epochs=100,\n",
        "                    validation_steps=np.ceil(float(len(validation_images)) / float(BATCH_SIZE)),\n",
        "                    validation_data = val_gen)\n",
        "model.save('mon_modele.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDA3AcOrGPmQ",
        "outputId": "bf34b4b7-83be-48ad-95d6-a1702c5e0b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/codeJournal/dwi1_aug_jpg/sub-strokecase0218__aug_1.jpg\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/drive/MyDrive/codeJournal/dwi1_aug_jpg/sub-strokecase0218__aug_1.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGx5HYpwbUmB"
      },
      "outputs": [],
      "source": [
        "train_dice = hist.history['dice_coef']\n",
        "val_dice = hist.history['val_dice_coef']\n",
        "#epochs = np.arange(1, 200 + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IulEq7a0bVMU",
        "outputId": "10508ca9-534f-4cd5-b15b-059e516a4a85"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0e588cfd2a2b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Dice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(epochs, train_dice, label='Training Dice')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "3thoR4eEOcB4",
        "outputId": "ceb9d3e6-19ac-461f-d8a3-4fb623d5b403"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6c3e2546f7a0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Extract the metrics from the history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dice_coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mval_dice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_dice_coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        }
      ],
      "source": [
        "# Assuming you have already trained your model and saved the history in histt\n",
        "\n",
        "# Extract the metrics from the history\n",
        "dice = hist.history['dice_coef']\n",
        "val_dice = hist.history['val_dice_coef']\n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "epochs_range = range(len(dice))  # Use the actual number of epochs\n",
        "\n",
        "# Create subplots\n",
        "plt.figure(figsize=(15, 5))  # Adjust the figsize to your preference\n",
        "\n",
        "# Plot Dice Coefficients\n",
        "plt.subplot(1, 2, 1)  # Changed from 1, 3, 1 to 1, 2, 1 for two plots side by side\n",
        "plt.plot(epochs_range, dice, label='Training Dice Coeff.', color='b')\n",
        "plt.plot(epochs_range, val_dice, label='Validation Dice Coeff.', color='r')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Dice Coefficient')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)  # Changed from 1, 3, 2 to 1, 2, 2 for two plots side by side\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy', color='g')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy', color='m')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()  # Ensures the plots don't overlap\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-py0KqAR_Qy"
      },
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "model = load_model('path/to/your/model.h5')  # Replace with the path to your model file\n",
        "\n",
        "# Function to preprocess an input image\n",
        "def preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize pixel values to be between 0 and 1\n",
        "    return img_array\n",
        "\n",
        "# Specify the path to the test image you want to use\n",
        "test_image_path = 'path/to/your/test/image.jpg'  # Replace with the path to your test image\n",
        "\n",
        "# Preprocess the test image\n",
        "input_image = preprocess_image(test_image_path, target_size=(224, 224))  # Adjust target_size based on your model's input size\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(input_image)\n",
        "\n",
        "# Decode and print the prediction\n",
        "# Example assumes a binary classification task; adjust accordingly for your problem\n",
        "if predictions[0][0] > 0.5:\n",
        "    print(\"Class: Positive\")\n",
        "else:\n",
        "    print(\"Class: Negative\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0cibJumRPC7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}